services:
  # Наш бот
  bot:
    build: .
    restart: always
    ports:
      - "3000:${PORT:-3000}"
    environment:
      - PORT=${PORT:-3000}
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - OLLAMA_URL=http://ollama:11434
      - MODEL_NAME=llama3.2:3b
    depends_on:
      - ollama

  # Нейросеть Ollama
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    volumes:
      - ollama_storage:/root/.ollama
    # Команда, которая сама скачает модель при первом запуске
    entrypoint: [ "/bin/sh", "-c" ]
    command: 
      - |
        ollama serve & 
        sleep 5 && 
        ollama pull llama3.2:3b && 
        wait

volumes:
  ollama_storage: